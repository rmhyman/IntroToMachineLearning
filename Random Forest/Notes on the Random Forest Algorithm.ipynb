{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Background\n",
    "**Random Forest** is a machine learning algorithm that uses multiple decision trees and takes the average over them to generate the result.  The Random Forest algorithm can be used as both a classification algorithm or as an regression model.  I will be discussing the algorithm as a classification algorithm since I have learned three others thus far (Naive Bayes, Support Vector Machines, Decision Trees).  The Random Forest classifier is known as an *ensemble method* because it a classifier that is built by multiple classifers.  Ensemble methods are used to make the classifer more generalized as well as to reduce some the variablitity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forest in sklearn\n",
    "The Random Forest Algorithm is found in *sklearn.ensemble* module of sklearn.  It has the same usage as other sklearn algorithms.  The two most important parameters for this classifier is **n_estimators** and **max_features**. *n_estimators* controls how many decision trees are used for the model.  The larger the number of trees, the better the predictability power.  It is worth noting that there is a threshold when this number becomes insignificant.  The *max_features* parameter is used to control the variance and bias tradeoff dial within this algorithm.  For classification algorithms, the best value for this parameter is \"sqrt\" which is the default value as well.  The lower this number, the lower the amount of variance, but also the increase in bias.  Below is example of its use in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "features_train = [[0,0],[1,1]]\n",
    "labels_train = [0,1]\n",
    "clf = RandomForestClassifier(n_estimators = 10, max_features = 'sqrt')\n",
    "clf.fit(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pros and Cons\n",
    "The strengths of this algorithm is that brings more generalization to decision trees by making predictions over a set of trees.  An obvious weakness of this is that can be complex and take a large amount of time to run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
